#!/usr/bin/python3
import numpy as np
import pandas as pd
import scipy as sp
from scipy.stats import ttest_1samp
import sys, os
import statsmodels
from statsmodels.stats.multitest import multipletests

#	This function takes the merged <30_Unused_BL_genes.csv output file generated by 6_Combined_30_Count_Replicates_List.py function 
#		and then the three replicate fitness files for a given enrichment condition generated as output from the 5_BarSeqProc_analyzeExp.py 
#		function and merges the fitness scores for each gene into one ‘_fitness_summary’ file.
#	This output file also provides the mean fitness score for each gene from the three replicates. Any genes where 0 read counts were identified
#		in any of the replicates (Unused_0ct_Exp_genes.csv files from 5_BarSeqProc_analyzeExp.py function) are eliminated from the merged table.
#		NOTE: these files are scanned for automatically in lines 84-88, so pay close attention that these files are named appropriately and change in the code, if needed
#		Genes trimmed in this way are listed in a _trimmed_genes.csv file.
#
#	A two-tailed one-sample sample t test is used to test whether the mean fitness value was significantly different from the value 
#		indicating no fitness change (fitness = 0) between enrichment condition and baseline. The t statistic and p-value for each gene are provided 
#		along with the individual and mean fitness scores in the ‘_Statistics.csv’ output file.
#	Finally, the p-values are adjusted for multiple testing according to the positive false discovery method from Benjamini & Hochberg, 1995 and Storey JD, 2003,
#		yielding q-values. The q-values were adjusted for monotonicity according to the method described by Yekutieli and Benjamini, 1999 
#		(https://www.sciencedirect.com/science/article/pii/S0378375899000415?via%3Dihub) and these values, along with the individual and mean fitness scores,
#		t statistic, p-value, and un-adjusted q-values re provided in the ‘_Statistics_sorted.csv’ output file.  
#	
#Usage: 
#	python3 PATH/7_Replicates_Table.py <PATH/merged_<30_Unused_BL_genes.csv> <PATH to fitness files> <Enrichment_Fitness_A_File> <Enrichment_Fitness_B_File> <Enrichment_Fitness_C_File>
#	
#	Input Files:
#		<PATH/merged_<30_Unused_BL_genes.csv> The file generated by 6_Combined_30_Count_Replicates_List.py, which is a csv file with a list of all the unused (<30 count) genes from
#			each of the baseline replicates, where duplicate names are deleted from the list.
#		<Enrichment_Fitness_A_File> The File generated from 5_BarSeqProc_analyzeExp.py that calculates gene fitness scores for the given replicate A enrichment condition
#		<Enrichment_Fitness_B_File> The File generated from 5_BarSeqProc_analyzeExp.py that calculates gene fitness scores for the given replicate B enrichment condition
#		<Enrichment_Fitness_C_File> The File generated from 5_BarSeqProc_analyzeExp.py that calculates gene fitness scores for the given replicate C enrichment condition
#
#	Output files:
#		<enrichment_title>_trimmed_genes.csv is a csv file with a list of all the unused genes (0 count in at least one enrichment replicate for the gene) in the analysis. 
#			The enrichment condition title is abstracted from the input file names (LBB_ML5-M9-GluB.GCCAAT uses the name ‘LB_ML5-M9-Glu’
#		<enrichment_title>_Fitness_Summary.csv is a csv file with a list of all the merged gene fitness data along with the mean fitness calculated for each gene between the three replicates. 
#		<enrichment_title>_Statistics.csv is a csv file with the same merged gene fitness data along with the mean fitness calculated for each gene between the three replicates as in 
#			the _Fitness_Summary file. Additionally, the t-score and p-value from a two-tailed one sample t-test is provided 
#		<enrichment_title>_Statistics_sorted.csv is a csv file with the same data as in the _Fitness_Summary file. Additionally, the p-values were sorted lowest to highest and the 
#			positive benjamini-hochburg correction for multiple testing was used to determine corresponding q-values and this column was added to the table. Finally a column where 
#			the q-values were adjusted for monotonicity according to the method described by Yekutieli and Benjamini, 1999 is provided.

# sysnames
Unusedcsv = sys.argv[1]
replicateDir = sys.argv[2]
replicateA = sys.argv[3]
replicateB = sys.argv[4]
replicateC = sys.argv[5]

os.chdir(replicateDir)
# load each allAnalyzedGenes.csv replicate files with pandas, reading only the first four columns 
# migrate data into a numpy array, calling labels and making an array of all genes (locus ID) in each file 
RepA = pd.read_csv(replicateA, header=None, usecols=[0,1,2])
RepB = pd.read_csv(replicateB, header=None, usecols=[0,1,2])
RepC = pd.read_csv(replicateC, header=None, usecols=[0,1,2])

RepA = np.array(RepA[:], dtype=str)
RepALabels = RepA[0,:] 
sizeA=RepA.shape[1]

RepB = np.array(RepB[:], dtype=str)
RepBLabels = RepB[0,:] 
sizeB=RepB.shape[1]

RepC = np.array(RepC[:], dtype=str)
RepCLabels = RepC[0,:] 
sizeC=RepC.shape[1]

#RepA-RepC genes array generated from the first column of the RepA-RepC numpy arrays, skipping the label row
RepAgenes = RepA[1:,0]
RepBgenes = RepB[1:,0]
RepCgenes = RepC[1:,0]

#open the csv file containing all the genes with <30 count in at least one of the replicates and assign it to array called eliminated

eliminate = pd.read_csv(Unusedcsv, header=None)
eliminate = np.array(eliminate[:], dtype=str)
eliminate = eliminate[:,0]

#append Unused_Oct_Exp_genes listed genes for all replicates, if these files were generated

#First, obtain the file names for the 0 count files, using input
noCountFileA = replicateA.split('_allAnalyzedGenes.csv')[0] + '_Unused_0ct_Exp_genes.csv'

noCountFileB = replicateB.split('_allAnalyzedGenes.csv')[0] + '_Unused_0ct_Exp_genes.csv'

noCountFileC = replicateC.split('_allAnalyzedGenes.csv')[0] + '_Unused_0ct_Exp_genes.csv'


#If the 0 count files exist for the replicates, append them to eliminate
if os.path.isfile('./'+noCountFileA): 
	noCountA = pd.read_csv(noCountFileA, header=None)
	noCountA = np.array(noCountA[:], dtype=str)
	noCountA = noCountA[:,0]
	eliminate = np.append(eliminate,noCountA)

if os.path.isfile('./'+noCountFileB): 
	noCountB = pd.read_csv(noCountFileB, header=None)
	noCountB = np.array(noCountB[:], dtype=str)
	noCountB = noCountB[:,0]
	eliminate = np.append(eliminate,noCountB)

if os.path.isfile('./'+noCountFileC): 
	noCountC = pd.read_csv(noCountFileC, header=None)
	noCountC = np.array(noCountC[:], dtype=str)
	noCountC = noCountC[:,0]
	eliminate = np.append(eliminate,noCountC)

#create a set of the eliminate genes
eliminate =set(eliminate)

#read through each array of gene names for each replicate and if it exists in the eliminated genes array, delete it from the replicate numpy array
NewRepA =[]
removeA =[]
for i in range(0,len(RepAgenes)):
	j=i+1   # Need to add one to i, since RepA-RepC contain a header
	if RepAgenes[i] in eliminate: 
		removeA.append([j])

NewRepA = np.delete(RepA, removeA, 0)

NewRepB=[]
removeB=[]
for i in range(0,len(RepBgenes)):
	j=i+1
	if RepBgenes[i] in eliminate: 
		removeB.append([j])

NewRepB = np.delete(RepB, removeB, 0)

NewRepC=[]
removeC=[]
for i in range(0,len(RepCgenes)):
	j=i+1
	if RepCgenes[i] in eliminate: 
		removeC.append([j])


NewRepC = np.delete(RepC, removeC, 0)

#Generate csv file called replicate_Fitness_table.csv for each replicate input file
locus = []
Rep_A_Fit = []
Rep_B_Fit = []
Rep_C_Fit = []

for i in range(1,len(NewRepA)):
	locus = np.append(locus, NewRepA[i,0])
	Rep_A_Fit = np.append(Rep_A_Fit, NewRepA[i,1])
	Rep_B_Fit = np.append(Rep_B_Fit, NewRepB[i,1])
	Rep_C_Fit = np.append(Rep_C_Fit, NewRepC[i,1])

#assemble all arrays into one numpy array
Combined_Fitness = np.column_stack((locus,Rep_A_Fit,Rep_B_Fit,Rep_C_Fit))

#find the mean for each gene's fitness
FitVals = np.array(Combined_Fitness[0:,1:], dtype=float)
meanVals = []
mean =[]
for i in range(0,len(FitVals)):
	mean = np.mean(FitVals[i])
	meanVals = np.append(meanVals,mean)
Fit_w_mean = np.column_stack((locus,Rep_A_Fit,Rep_B_Fit,Rep_C_Fit,meanVals))

#NewRepA-NewRepC genes array generated from the first column of the NewRepA-NewRepC numpy arrays, skipping the label row
NewRepAgenes = NewRepA[1:,0]
NewRepBgenes = NewRepB[1:,0]
NewRepCgenes = NewRepC[1:,0]

GenesRemovedA = []
GenesRemovedA=list(set(RepAgenes) - set(NewRepAgenes))

GenesRemovedB = []
GenesRemovedB=list(set(RepBgenes) - set(NewRepBgenes))

GenesRemovedC = []
GenesRemovedC=list(set(RepCgenes) - set(NewRepCgenes))

#switch back to output directory
os.chdir("../../5_Merge_Replicates/")

#assemble all genes removed arrays into one numpy array
AllGenesRemoved = np.array([('replicate_A',GenesRemovedA),('replicate_B',GenesRemovedB),('replicate_C',GenesRemovedC)], dtype="object")

#Generate a csv file with a summary of genes that were deleted from each replicate call trimmed_genes.csv
#first, come up with a unique identifier for each index set
uniqID = replicateA.split('A.')[0]

np.savetxt((uniqID +'_trimmed_genes.csv'), AllGenesRemoved, delimiter=',', fmt='%s')

#Save a Fitness Score Summary File
np.savetxt((uniqID+'_Fitness_Summary.csv'), Fit_w_mean, delimiter=',', fmt='%s', header='geneName,NormGeneFit_A,NormGeneFit_B,NormGeneFit_C,mean')


###
#PERFORM A TWO_SIDED_ONE_SAMPLE_T_TEST ON THE AVERAGE_NORMALIZED FITNESS VALUES
###

GeneLabels = []
for i in range(0,len(Combined_Fitness)):
	GeneLabels = np.append(GeneLabels,Combined_Fitness[i,0])

FitVals = np.array(Combined_Fitness[0:,1:], dtype=float)

#Find the mean, t statistic and p_value for each gene, use the two_sided one sample t test
mean = []
meanVals = []
tscore = []
tscoreArray = []
pvalue = []
pvalueArray = []
for i in range(0,len(FitVals)):
	mean = np.mean(FitVals[i])
	tscore, pvalue = ttest_1samp(FitVals[i], popmean=0)
	pvalue = f"{pvalue:.9f}"
	meanVals = np.append(meanVals,mean)
	tscoreArray = np.append(tscoreArray,tscore)
	pvalueArray = np.append(pvalueArray,pvalue)

#Build everything into a numpy array
structuredStatArr = []
structuredStatArr = np.column_stack((GeneLabels, FitVals, meanVals,tscoreArray,pvalueArray))

#sort the statistics array by p-value so that we can perform the benjamini-hochburg procedure for correcting false discovery rate 
ind=np.argsort(structuredStatArr[:,-1])
SortstructuredStatArr = structuredStatArr[ind]

#Partition off each element of the array
Sorted_pvals = np.array(SortstructuredStatArr[0:,6], dtype=float)
GeneLabels = np.array(SortstructuredStatArr[0:,0])
FitVals = np.array(SortstructuredStatArr[0:,1:4])
meanVals = np.array(SortstructuredStatArr[0:,4])
tscoreArray = np.array(SortstructuredStatArr[0:,5])

#Obtain the q-value according to the positive Benjamini-Hochberg method: q(i)=p(i)*N/i
q = []
qVals = []
N=len(Sorted_pvals)
for i in range(1,N+1):
	p = Sorted_pvals[i-1]
	q=p*N/i
	qVals=np.append(qVals,q)

#Importantly, the last step involves replacing q(i) with the lowest value among all lower-rank Q-values that were calculated.  
# This is because q(i) is not a monotonic function, so moving to a lower p-value might actually result in a higher Q-value, which doesn't make sense. 
# This adjustment ensures monotonically decreasing Q-values as explained: 

# https://riffyn.com/blog/false-discovery-rate or
# https://brainder.org/2011/09/05/fdr-corrected-fdr-adjusted-p-values/

# Published in Yekutieli and Benjamini, 1999: https://www.sciencedirect.com/science/article/pii/S0378375899000415?via%3Dihub

# This process involves finding the minimum q value that follows the current q value and adjusting the value accordingly
# such that q*(i)=q(k), k >/= i, where q(k) =  p(k)*N/k

#Make a new array called sort_qVal
sort_qVal=[None]*len(qVals)

for i in range(0,len(qVals)):
	sort_qVal[i] =qVals[i]

#Iterate through the qVal array and replace an element with the minimum value that follows it, if one exists 
minVal = []
for i in range(0,len(qVals)):
    minVal = min(qVals[i:])
    if minVal < sort_qVal[i]:
    	sort_qVal[i]=minVal

#Assemble back into a table
SortstructuredStatArr = np.column_stack((GeneLabels,FitVals,meanVals,tscoreArray,Sorted_pvals,qVals,sort_qVal))

#print the output of the numpy array
np.savetxt((uniqID+'_Statistics.csv'), structuredStatArr, delimiter=',', fmt='%s', header='geneName,NormFit_A,NormFit_B,NormFit_C,mean,t_stat,p_value')
np.savetxt((uniqID+'_Statistics_sorted.csv'), SortstructuredStatArr, delimiter=',', fmt='%s', header='geneName,NormFit_A,NormFit_B,NormFit_C,mean,t_stat,p_value,q-value_BH_method,adjusted_q-value')

